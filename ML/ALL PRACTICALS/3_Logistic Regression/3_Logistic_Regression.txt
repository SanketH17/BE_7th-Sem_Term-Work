import numpy
x= numpy.array([1,3.2,2.4,3.5,2.5,3.6,2.04,3.04,2.13,3.15]).reshape(-1,1)
y= numpy.array([1,0,1,0,1,0,1,0,1,0]).reshape(-1,1)
from sklearn import datasets, linear_model, metrics
f=linear_model.LogisticRegression()
f.fit(x,y)
print(f.coef_)
p=f.predict(numpy.array([2.16]).reshape(-1,1))
print(p)

'''
Logistic regression aims to solve classification problems. 
It does this by predicting categorical outcomes, unlike linear regression that predicts a continuous outcome. 
In the simplest case there are two outcomes, which is called binomial, an example of which is predicting if a tumor is malignant 
or benign.Other cases have more than two outcomes to classify, in this case it is called multinomial.
 A common example for multinomial logistic regression would be predicting the class of an iris flower between 3 different species.
 General Terms: Below are statistical concepts commonly used in testing. Sigmoid: A sigmoid function is an activation function. 
The output of the sigmoid function is always between a range of 0 to1. 

Optimization: 
optimization is a process that maximizes or minimizes 
the variables or parameters of a machine learning model with respect to the selected loss function.
'''